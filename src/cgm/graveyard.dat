/*void cpu_l1_cache_access_puts(struct cache_t *cache, struct cgm_packet_t *message_packet){

	struct cgm_packet_t *miss_status_packet;
	enum cgm_access_kind_t access_type;
	unsigned int addr = 0;
	long long access_id = 0;
	int set = 0;
	int tag = 0;
	unsigned int offset = 0;
	int way = 0;
	int state = 0;

	int *set_ptr = &set;
	int *tag_ptr = &tag;
	unsigned int *offset_ptr = &offset;
	int *way_ptr = &way;
	int *state_ptr = &state;

	int mshr_row = -1;

	int i = 0;

	//the packet is from the L2 cache
	access_type = message_packet->access_type;
	addr = message_packet->address;
	access_id = message_packet->access_id;

	//probe the address for set, tag, and offset.
	assert(addr != NULL);
	cgm_cache_decode_address(cache, addr, set_ptr, tag_ptr, offset_ptr);

	CGM_DEBUG(CPU_cache_debug_file, "%s access_id %llu cycle %llu puts\n", cache->name, access_id, P_TIME);

	//charge the delay for writing cache block
	cgm_cache_set_block(cache, *set_ptr, *way_ptr, *tag_ptr, cache_block_shared);
	P_PAUSE(cache->latency);

	//get the mshr status
	mshr_row = mshr_get_status(cache, set_ptr, tag_ptr, access_id);
	if(mshr_row == -1)
	{
		printf("%s crashing %llu access_id %llu type %s\n", cache->name, P_TIME, access_id, str_map_value(&cgm_mem_access_strn_map, message_packet->cpu_access_type));
		mshr_dump(cache);
		assert(mshr_row != -1);
	}

	//check the number of entries in the mshr row
	assert(list_count(cache->mshrs[mshr_row].entires) == cache->mshrs[mshr_row].num_entries);
	assert(cache->mshrs[mshr_row].num_entries > 0);

	CGM_DEBUG(mshr_debug_file, "%s access_id %llu cycle %llu mshr_row %d num_entries %d\n", cache->name, access_id, P_TIME, mshr_row, cache->mshrs[mshr_row].num_entries);

	//move them to the retry queue
	for(i = 0; i < cache->mshrs[mshr_row].num_entries; i++)
	{
		miss_status_packet = list_dequeue(cache->mshrs[mshr_row].entires);

		CGM_DEBUG(mshr_debug_file, "%s access_id %llu coalesced %d tag %d set %d\n",
				cache->name, miss_status_packet->access_id, miss_status_packet->coalesced, miss_status_packet->tag, miss_status_packet->set);

		assert(miss_status_packet != NULL);
		//assert(miss_status_packet->address != 0);

		if (miss_status_packet->access_id == access_id)
		{
			//this is the first entry and was not coalesced
			//assert(miss_status_packet->access_id == access_id);
			assert(miss_status_packet->coalesced == 0);

			//we can put either the message_packet or miss_status_packet in the retry queue.
			message_packet->access_type = cgm_access_retry;
			list_remove(cache->last_queue, message_packet);
			list_enqueue(cache->retry_queue, message_packet);

		}
		else
		{
			//this is a coalesced packet
			if(miss_status_packet->coalesced != 1)
			{
				printf("breaking access_id %llu cycle %llu\n", access_id, P_TIME);
				printf("i %d miss sp %llu, coalesced %d\n", i, miss_status_packet->access_id, miss_status_packet->coalesced);

				mshr_dump(cache);

				STOP;
			}

			assert(miss_status_packet->coalesced == 1);

			//drop it into the retry queue
			list_enqueue(cache->retry_queue, miss_status_packet);

		}
	}

	//advance myself by the number of packets.
	long long time = etime.count;  :-P
	for(i = 0; i < cache->mshrs[mshr_row].num_entries; i ++)
	{
		time += 2;
		future_advance(cache->ec_ptr, time);
	}

	//clear the mshr row for future use
	mshr_clear(&(cache->mshrs[mshr_row]));

	return;
}*/


//struct cgm_packet_status_t *mshr_remove(struct cache_t *cache);



/*struct cgm_packet_status_t *mshr_remove(struct cache_t *cache){

	int i = 0;
	struct cgm_packet_status_t *miss_status_packet;
	struct cgm_packet_status_t *message_packet;


	list_enqueue(cache->retry_queue, message_packet);



	LIST_FOR_EACH(cache->mshr, i)
	{
		mshr_packet = list_get(cache->mshr, i);

		if (mshr_packet->access_id == access_id)
		{
			return list_remove_at(cache->mshr, i);
		}
	}

	return NULL;
}*/



//this needs to be deleted
//int cache_get_state(struct cache_t *cache, enum cgm_access_kind_t access_type, int *tag_ptr, int *set_ptr, unsigned int *offset_ptr, int *way_ptr, int *state_ptr);


//void cpu_l1_cache_access_puts(struct cache_t *cache, struct cgm_packet_t *message_packet);

/*int cache_get_state(struct cache_t *cache, enum cgm_access_kind_t access_type, int *tag_ptr, int *set_ptr, unsigned int *offset_ptr, int *way_ptr, int *state_ptr){

	cache_block_invalid = 0
	cache_block_noncoherent = 1
	cache_block_modified = 2
	cache_block_owned = 3
	cache_block_exclusive = 4
	cache_block_shared = 5

	int cache_status;

	//stats


	//find the block in the cache and get it's state
	cache_status = cgm_cache_find_block(cache, tag_ptr, set_ptr, offset_ptr, way_ptr, state_ptr);

	printf("cache_status %d\n", cache_status);
	getchar();

	//hit and state is M, E, or S we are done at this level of cache
	if((cache_status == 1 && *state_ptr == 2) || (cache_status == 1 && *state_ptr == 4 ) || (cache_status == 1 && *state_ptr == 5))
	{
		//stats
		cache->hits++;

		//done, respond to requester.
		return 1;
	}
	//hit and state is invalid (miss)
	else if(cache_status == 1 && *state_ptr == 0)
	{
		//stats
		cache->invalid_hits++;

		//treat this like a miss
		return 2;

	}
	//the cache block is not present m the cache (miss)
	else if(cache_status == 0)
	{
		//stats
		cache->misses++;

		return 3;
	}
	else if (cache_status == 1 && *state_ptr == 1)
	{
		printf("CRASHING cache_status %d state_ptr %d\n", cache_status, *state_ptr);
		getchar();
		fatal("cache_mesi_load() non cached state\n");
	}
	else
	{
		printf("CRASHING cache_status %d state_ptr %d\n", cache_status, *state_ptr);
		getchar();
		fatal("cache_mesi_load() something went wrong here\n");
	}

	return 0;

}*/


//fixed
	//===============================================
	/*if(mshr_status >= 0)
	{
		we have outstanding mshr requests so set the retry state bit
		*retry_ptr = cache->mshrs[mshr_status].num_entries;
		assert(*retry_ptr > 0);
	}

	//move the access and any coalesced accesses to the retry queue.
	for(i = 0; i < *retry_ptr; i++)
	{
		if( i == 0)
		{
			//move current message_packet to retry queue
			message_packet->access_type = cgm_access_retry;
			list_remove(cache->last_queue, message_packet);
			list_enqueue(cache->retry_queue, message_packet);
			advance(&l2_cache[cache->id]);
		}
		else if( i > 0)
		{
			miss_status_packet = list_remove_at(cache->mshrs[mshr_status].entires, i);
			miss_status_packet->coalesced_packet->access_type = cgm_access_retry;
			list_enqueue(cache->retry_queue, miss_status_packet->coalesced_packet);
			free(miss_status_packet);
			advance(&l2_cache[cache->id]);
		}
	}

	mshr_clear(&(cache->mshrs[mshr_status]));*/










//fixed
		/*if(mshr_status == 1)
		{
			//access is unique in the MSHR
			//while the next level's queue is full stall
			while(!switch_can_access(switches[cache->id].north_queue))
			{
				P_PAUSE(1);
			}

			CGM_DEBUG(cache_debug_file, "l2_cache[%d] access_id %llu cycle %llu miss switch north queue free size %d\n",
					cache->id, access_id, P_TIME, list_count(switches[cache->id].north_queue));

			//send to L3 cache over switching network add source and dest here
			//star todo send to correct l3 dest
			message_packet->access_type = cgm_access_gets_i;
			message_packet->src_name = cache->name;
			message_packet->source_id = str_map_string(&node_strn_map, cache->name);
			message_packet->dest_name = l3_caches[cache->id].name;
			message_packet->dest_id = str_map_string(&node_strn_map, l3_caches[cache->id].name);


			list_remove(cache->last_queue, message_packet);
			CGM_DEBUG(cache_debug_file, "l2_cache[%d] access_id %llu cycle %llu removed from %s size %d\n",
					cache->id, access_id, P_TIME, cache->last_queue->name, list_count(cache->last_queue));
			list_enqueue(switches[cache->id].north_queue, message_packet);

			future_advance(&switches_ec[cache->id], WIRE_DELAY(switches[cache->id].wire_latency));

			CGM_DEBUG(cache_debug_file, "l2_cache[%d] access_id %llu cycle %llu l2_cache[%d] as %s\n",
				cache->id, access_id, P_TIME, cache->id, (char *)str_map_value(&cgm_mem_access_strn_map, message_packet->access_type));

			CGM_DEBUG(protocol_debug_file, "Access_id %llu cycle %llu l1_i_cache[%d] Miss\tSEND l2_cache[%d] -> %s\n",
				access_id, P_TIME, cache->id, cache->id, (char *)str_map_value(&cgm_mem_access_strn_map, message_packet->access_type));

		}*/


//==================================


			/*//stats
			if(access_type == cgm_access_fetch)
				l1_i_caches[my_pid].fetches++;

			if(access_type == cgm_access_retry)
				l1_i_caches[my_pid].retries++;

			//memory access from CPU
			addr = message_packet->address;
			access_id = message_packet->access_id;

			//probe the address for set, tag, and offset.
			cgm_cache_decode_address(&(l1_i_caches[my_pid]), addr, set_ptr, tag_ptr, offset_ptr);

			CGM_DEBUG(cache_debug_file,"l1_i_cache[%d] access_id %llu cycle %llu as %s addr 0x%08u, tag %d, set %d, offset %u\n",
					my_pid, access_id, P_TIME, (char *)str_map_value(&cgm_mem_access_strn_map, access_type), addr, *tag_ptr, *set_ptr, *offset_ptr);

			//get the block and the state of the block and charge a cycle
			cache_status = cgm_cache_find_block(&(l1_i_caches[my_pid]), tag_ptr, set_ptr, offset_ptr, way_ptr, state_ptr);
			P_PAUSE(2);

			//L1 I Cache Hit!
			if(cache_status == 1 && *state_ptr != 0)
			{
				CGM_DEBUG(cache_debug_file, "\tl1_i_cache[%d] access_id %llu cycle %llu hit\n", my_pid, access_id, P_TIME);

				if(access_type == cgm_access_retry)
					retry_ptr--;

				if(access_type == cgm_access_fetch)
					l1_i_caches[my_pid].hits++;

				//remove packet from cache queue, global queue, and simulator memory
				//note cycle already charged

				list_remove(l1_i_caches[my_pid].last_queue, message_packet);
				remove_from_global(access_id);
				free(message_packet);

			}
			//L1 I Cache Miss!
			else if(cache_status == 0 || *state_ptr == 0)
			{
				//all mshr based retires should be hits
				//star todo there is a bug here 1 access fails retry in our MM.
				assert(message_packet->access_type != cgm_access_retry);

				if(access_type == cgm_access_fetch)
					l1_i_caches[my_pid].misses++;

				CGM_DEBUG(cache_debug_file, "\tl1_i_cache[%d] access_id %llu cycle %llu miss\n", my_pid, access_id, P_TIME);

				miss_status_packet = miss_status_packet_create(message_packet->access_id, message_packet->access_type, set, tag, offset);
				mshr_status = mshr_set(&(l1_i_caches[my_pid]), miss_status_packet, message_packet);

				CGM_DEBUG(cache_debug_file, "\tl1_i_cache[%d] access_id %llu cycle %llu miss mshr status %d\n", my_pid, access_id, P_TIME, mshr_status);

				if(mshr_status == 1)
				{
					//access is unique in the MSHR
					//while the next level of cache's in queue is full stall
					while(!cache_can_access_top(&l2_caches[my_pid]))
					{
						P_PAUSE(1);
					}

					CGM_DEBUG(cache_debug_file, "\tl1_i_cache[%d] access_id %llu cycle %llu miss l2 queue free\n", my_pid, access_id, P_TIME);

					change the access type for the coherence protocol and drop into the L2's queue
					remove the access from the l1 cache queue and place it in the l2 cache ctrl queue
					message_packet->access_type = cgm_access_gets_i;
					list_remove(l1_i_caches[my_pid].last_queue, message_packet);
					list_enqueue(l2_caches[my_pid].Rx_queue_top, message_packet);

					CGM_DEBUG(cache_debug_file, "\tl1_i_cache[%d] access_id %llu cycle %llu l2_cache[%d] -> %s\n",
							my_pid, access_id, P_TIME, my_pid, (char *)str_map_value(&cgm_mem_access_strn_map, message_packet->access_type));

					//advance the L2 cache adding some wire delay time.
					future_advance(&l2_cache[my_pid], (etime.count + (l2_caches[my_pid].wire_latency * 2)));
				}
				else if(mshr_status == 0)
				{
					//mshr is full so we can't progress, retry.
					message_packet->access_type = cgm_access_retry;
					future_advance(&l1_i_cache[my_pid], (etime.count + 2));

				}
				else
				{
					//access was coalesced. For now do nothing until later.
				}

				//done
			}
		}*/

		/*else if(access_type == cgm_access_puts)
		{
			//the packet is from the L2 cache
			addr = message_packet->address;
			access_id = message_packet->access_id;

			//probe the address for set, tag, and offset.
			cgm_cache_decode_address(&(l1_i_caches[my_pid]), addr, set_ptr, tag_ptr, offset_ptr);

			CGM_DEBUG(cache_debug_file, "l1_i_cache[%d] access_id %llu cycle %llu puts\n", my_pid, access_id, P_TIME);

			//charge the delay for writing cache block
			cgm_cache_set_block(&l1_i_caches[my_pid], *set_ptr, *way_ptr, tag, cache_block_shared);
			P_PAUSE(1);

			//get the mshr status
			mshr_status = mshr_get(&l1_i_caches[my_pid], set_ptr, tag_ptr);
			assert(mshr_status != -1);

			if(mshr_status >= 0)
			{
				we have outstanding mshr requests so set the retry state bit
				*retry_ptr = l1_i_caches[my_pid].mshrs[mshr_status].num_entries;
				//printf("retry_ptr %d\n", *retry_ptr);
				assert(*retry_ptr > 0);
			}

			advance_time = etime.count + 2;

			//move the access and any coalesced accesses to the retry queue.
			for(i = 0; i < *retry_ptr; i++)
			{
				if( i == 0)
				{
					//move current message_packet to retry queue
					message_packet->access_type = cgm_access_retry;
					list_remove(l1_i_caches[my_pid].next_queue, message_packet);
					list_enqueue(l1_i_caches[my_pid].retry_queue, message_packet);

					//printf("list count %d\n", list_count(l1_i_caches[my_pid].retry_queue));

					advance(&l1_i_cache[my_pid]);
				}
				else if( i > 0)
				{
					miss_status_packet = list_remove_at(l1_i_caches[my_pid].mshrs[mshr_status].entires, i);
					list_enqueue(l1_i_caches[my_pid].retry_queue, miss_status_packet->coalesced_packet);
					free(miss_status_packet);
					advance_time += 2;
					advance(&l1_i_cache[my_pid]);
				}
			}

			//clear the mshr row for future use
			mshr_clear(&l1_i_caches[my_pid].mshrs[mshr_status]);
			//done.
		}


	}*/


else if(cache_status == 0 || *state_ptr == 0)
{

				// L2 Cache Miss!
				l2_caches[my_pid].misses++;

				/*printf("access id %llu l1 miss\n", access_id);
				getchar();*/


				//star todo check on size of MSHR
				mshr_packet = status_packet_create();

				//drop a token in the mshr queue
				//star todo add some detail to this so we can include coalescing
				//star todo have an MSHR hit advance the cache and clear out the request.
				mshr_packet->access_type = message_packet->access_type;
				mshr_packet->access_id = message_packet->access_id;
				mshr_packet->in_flight = message_packet->in_flight;
				list_enqueue(l2_caches[my_pid].mshr, mshr_packet);


				message_packet->access_type = cgm_access_puts;

				//set the block now for testing///////////
				cgm_cache_set_block(&(l2_caches[my_pid]), *set_ptr, *way_ptr, tag, cache_block_shared);
				///////////////////////////////////////////

				list_remove(l2_caches[my_pid].Rx_queue_top, message_packet);
				list_enqueue(l1_i_caches[my_pid].Rx_queue_top, message_packet);

				future_advance(&l1_i_cache[my_pid], (etime.count + l1_i_caches[my_pid].wire_latency));
			}
			
			
			
//printf("After probe addr 0x%08x\n", addr);

	/*printf("cache->log_block_size = %d\n",cache->log_block_size);
	printf("cache->block_mask %d\n", cache->block_mask);
	printf("\n");*/
	
	//notes this is useing the tag and indx to calculate set location.

	/*printf("---set_ptr---\n");
	printf("Addr 0x%08x\n", addr);
	printf("(addr >> cache->log_block_size) = 0x%08x\n", addr >> cache->log_block_size);
	printf("set_ptr %d\n", (addr >> cache->log_block_size) % cache->num_sets);
	printf("---set_ptr---\n");*/

	/*printf("---tag_ptr---\n");
	printf("Addr 0x%08X\n", addr);
	printf("~(cache->block_mask) 0x%08x\n", ~(cache->block_mask));
	printf("addr & ~(cache->block_mask) 0x%08x\n", addr & ~(cache->block_mask));
	printf("tag %d\n", *tag_ptr);
	printf("---tag_ptr---\n");
	getchar();*/

	/*printf("---offset_ptr---\n");
	printf("Addr 0x%08x\n", addr);
	printf("(cache->block_mask) 0x%08x\n", (cache->block_mask));
	printf("addr & (cache->block_mask) 0x%08x\n", addr & addr & (cache->block_mask));
	printf("---offset_ptr---\n");
	getchar();*/
	
	